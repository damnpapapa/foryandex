{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d618156-edac-4ce8-ba6a-3694ec2b04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "folder_path = 'anova'\n",
    "\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]  # или .xlsx, в зависимости от формата файлов\n",
    "\n",
    "# Словарь для хранения результатов\n",
    "results = {}\n",
    "\n",
    "# Обработка каждого файла\n",
    "for file in files:\n",
    "    # Чтение данных из файла\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    data = pd.read_csv(file_path)  # или pd.read_excel(file_path), если файлы в формате Excel\n",
    "\n",
    "    # Убедитесь, что переменные condition и slider_2.response существуют\n",
    "    if 'condition' in data.columns and 'slider_2.response' in data.columns:\n",
    "        # Группировка данных по категории и вычисление среднего\n",
    "        averages = data.groupby('condition')['slider_2.response'].mean()\n",
    "\n",
    "        # Сохранение результатов в словарь\n",
    "        respondent_id = file.split('.')[0]  # Предполагаем, что имя файла - это ID респондента\n",
    "        results[respondent_id] = {\n",
    "            'emot': averages.get('emot', None),\n",
    "            'less': averages.get('less', None),\n",
    "            'filler': averages.get('filler', None)\n",
    "        }\n",
    "\n",
    "# Преобразование результатов в DataFrame\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "results_df.columns = ['Respondent', 'Emot', 'Less', 'Filler']\n",
    "\n",
    "# Сохранение в Excel файл\n",
    "results_df.to_excel('averages_by_category.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79b1ab6-972c-47c9-8abb-8dbbcba69e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results:\n",
      "               sum_sq     df           F        PR(>F)\n",
      "Condition  248.583651    2.0  444.072808  1.086495e-53\n",
      "Residual    31.067862  111.0         NaN           NaN\n",
      "\n",
      "Effect Size (η²): 0.8889050822887414\n",
      "\n",
      "Результаты ANOVA значимы: существует статистически значимая разница между группами.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Загрузка данных из Excel файла\n",
    "data = pd.read_excel('averages_by_category.xlsx')\n",
    "\n",
    "# Преобразование данных в длинный формат для ANOVA\n",
    "data_melted = data.melt(id_vars=['Respondent'], value_vars=['Emot', 'Less', 'Filler'],\n",
    "                         var_name='Condition', value_name='Score')\n",
    "\n",
    "# Выполнение однофакторного дисперсионного анализа\n",
    "model = ols('Score ~ Condition', data=data_melted).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Вывод результатов ANOVA\n",
    "print(\"ANOVA Results:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Расчет размера эффекта η²\n",
    "ss_total = anova_table['sum_sq'].sum()\n",
    "ss_between = anova_table['sum_sq']['Condition']\n",
    "eta_squared = ss_between / ss_total\n",
    "\n",
    "print(\"\\nEffect Size (η²):\", eta_squared)\n",
    "\n",
    "# Интерпретация результатов\n",
    "if anova_table['PR(>F)']['Condition'] < 0.05:\n",
    "    print(\"\\nРезультаты ANOVA значимы: существует статистически значимая разница между группами.\")\n",
    "else:\n",
    "    print(\"\\nРезультаты ANOVA незначимы: нет статистически значимой разницы между группами.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9b8ecd-5817-45d5-91ba-6fba4e0240ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results:\n",
      "               sum_sq     df           F        PR(>F)\n",
      "Condition  248.583651    2.0  444.072808  1.086495e-53\n",
      "Residual    31.067862  111.0         NaN           NaN\n",
      "\n",
      "Partial Effect Size (ηp²): 0.8889050822887414\n",
      "\n",
      "Результаты One-Way ANOVA значимы: существует статистически значимая разница между группами.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Загрузка данных из Excel файла\n",
    "data = pd.read_excel('averages_by_category.xlsx')\n",
    "\n",
    "# Преобразование данных в длинный формат для ANOVA\n",
    "data_melted = data.melt(id_vars=['Respondent'], value_vars=['Emot', 'Less', 'Filler'],\n",
    "                         var_name='Condition', value_name='Score')\n",
    "\n",
    "# Выполнение однофакторного дисперсионного анализа (One-Way ANOVA)\n",
    "model = ols('Score ~ Condition', data=data_melted).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Вывод результатов ANOVA\n",
    "print(\"ANOVA Results:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Расчет размера эффекта η²\n",
    "ss_total = anova_table['sum_sq'].sum()\n",
    "ss_between = anova_table['sum_sq']['Condition']\n",
    "ss_within = anova_table['sum_sq']['Residual']\n",
    "\n",
    "# Расчет частичного η²\n",
    "eta_partial_squared = ss_between / (ss_between + ss_within)\n",
    "\n",
    "print(\"\\nPartial Effect Size (ηp²):\", eta_partial_squared)\n",
    "\n",
    "# Интерпретация результатов\n",
    "if anova_table['PR(>F)']['Condition'] < 0.05:\n",
    "    print(\"\\nРезультаты One-Way ANOVA значимы: существует статистически значимая разница между группами.\")\n",
    "else:\n",
    "    print(\"\\nРезультаты One-Way ANOVA незначимы: нет статистически значимой разницы между группами.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4a64b5-2584-4e3a-aa72-b60e923b59e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum_sq     df           F        PR(>F)\n",
      "C(Category)  248.583651    2.0  444.072808  1.086495e-53\n",
      "Residual      31.067862  111.0         NaN           NaN\n",
      "Размер эффекта η²: 0.8889\n",
      "Частичный размер эффекта ηp²: 0.8889\n",
      "Интерпретация размера эффекта: Большой эффект\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "\n",
    "# Загрузка данных из файла\n",
    "data = pd.read_excel('averages_by_category.xlsx')\n",
    "\n",
    "# Преобразуем данные в длинный формат\n",
    "data_long = pd.melt(data, id_vars=['Respondent'], value_vars=['Emot', 'Less', 'Filler'],\n",
    "                    var_name='Category', value_name='Score')\n",
    "\n",
    "# Выполнение однофакторного дисперсионного анализа\n",
    "model = ols('Score ~ C(Category)', data=data_long).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Вывод результатов ANOVA\n",
    "print(anova_table)\n",
    "\n",
    "# Расчет частичного размера эффекта ηp²\n",
    "ss_total = sum((data_long['Score'] - data_long['Score'].mean())**2)\n",
    "ss_between = anova_table['sum_sq']['C(Category)']\n",
    "ss_within = anova_table['sum_sq']['Residual']\n",
    "\n",
    "eta_squared = ss_between / ss_total\n",
    "eta_partial_squared = ss_between / (ss_between + ss_within)\n",
    "\n",
    "print(f\"Размер эффекта η²: {eta_squared:.4f}\")\n",
    "print(f\"Частичный размер эффекта ηp²: {eta_partial_squared:.4f}\")\n",
    "\n",
    "# Интерпретация результата\n",
    "if eta_partial_squared < 0.01:\n",
    "    effect_size_interpretation = \"Малый эффект\"\n",
    "elif eta_partial_squared < 0.06:\n",
    "    effect_size_interpretation = \"Средний эффект\"\n",
    "else:\n",
    "    effect_size_interpretation = \"Большой эффект\"\n",
    "\n",
    "print(f\"Интерпретация размера эффекта: {effect_size_interpretation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4373a88b-6e1b-401f-a397-32f1da191e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emot1: Statistic=0.9312158823013306, p-value=0.02191239222884178, is normal=False\n",
      "Less1: Statistic=0.9529996514320374, p-value=0.11183279007673264, is normal=True\n",
      "Filler1: Statistic=0.9154956340789795, p-value=0.007190981414169073, is normal=False\n",
      "Emot: Statistic=0.9312157034873962, p-value=0.0219121053814888, is normal=False\n",
      "Less: Statistic=0.952999472618103, p-value=0.11183127015829086, is normal=True\n",
      "Filler: Statistic=0.9154956340789795, p-value=0.007190981414169073, is normal=False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Загрузка данных из Excel-файла\n",
    "file_path = 'averages_by_category1.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Переменные для проверки\n",
    "variables = ['Emot1', 'Less1', 'Filler1', 'Emot', 'Less', 'Filler']\n",
    "\n",
    "# Проверка нормальности для каждой переменной\n",
    "results = {}\n",
    "for var in variables:\n",
    "    if var in data.columns:\n",
    "        stat, p_value = stats.shapiro(data[var].dropna())  # Удаляем NaN значения\n",
    "        results[var] = {\n",
    "            'statistic': stat,\n",
    "            'p_value': p_value,\n",
    "            'is_normal': p_value > 0.05  # Нулевая гипотеза о нормальности\n",
    "        }\n",
    "    else:\n",
    "        results[var] = 'Variable not found in data'\n",
    "\n",
    "# Вывод результатов\n",
    "for var, result in results.items():\n",
    "    if isinstance(result, dict):\n",
    "        print(f\"{var}: Statistic={result['statistic']}, p-value={result['p_value']}, is normal={result['is_normal']}\")\n",
    "    else:\n",
    "        print(f\"{var}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a5b8bd-a610-458d-a5ae-1a7bbaceebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attitude           Variable  Statistic       p-value\n",
      "0      pro     Persuasiveness      656.0  1.219334e-02\n",
      "1      pro            Sharing      689.0  2.848530e-03\n",
      "2      pro         Congruence      634.0  2.813865e-02\n",
      "3      pro  Authoritativeness      769.0  2.018177e-05\n",
      "4      pro              Trust      521.5  5.643605e-01\n",
      "5     anti     Persuasiveness      780.5  6.438364e-07\n",
      "6     anti            Sharing      730.0  2.129929e-05\n",
      "7     anti         Congruence      703.0  1.425219e-04\n",
      "8     anti  Authoritativeness      782.0  3.883092e-07\n",
      "9     anti              Trust      704.0  1.341404e-04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('0.csv')\n",
    "\n",
    "# Переменные для анализа\n",
    "variables = ['Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust']\n",
    "#speakers = ['PROC', 'SHUC']\n",
    "attitudes = ['pro', 'anti']\n",
    "results = []\n",
    "\n",
    "# Разделение данных по Attitude и выполнение теста Манна-Уитни\n",
    "for attitude in attitudes:\n",
    "    #group_data = data[data['Speaker'] == speaker]\n",
    "    group_data = data[data['Attitude'] == attitude]\n",
    "    \n",
    "    for variable in variables:\n",
    "        pro_values = group_data[group_data['Speaker'] == 'PROC'][variable]\n",
    "        anti_values = group_data[group_data['Speaker'] == 'SHUC'][variable]\n",
    "        \n",
    "        # Выполнение теста Манна-Уитни\n",
    "        stat, p_value = mannwhitneyu(pro_values, anti_values)\n",
    "        \n",
    "        # Сохранение результатов\n",
    "        results.append({\n",
    "            'Attitude': attitude,\n",
    "            'Variable': variable,\n",
    "            'Statistic': stat,\n",
    "            'p-value': p_value\n",
    "        })\n",
    "\n",
    "# Создание DataFrame с результатами\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_df)\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "results_df.to_excel('11.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aebadd0-b735-4c9f-80b5-bdf680627fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652392\n",
      "         Iterations 5\n",
      "Результаты логистической регрессии сохранены в файл '12.xlsx'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/kkh8vd7s0kzdck7rptzdy4sh0000gn/T/ipykernel_36729/1197624218.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('01.csv')\n",
    "\n",
    "# Замена запятых на точки во всех переменных\n",
    "data = data.applymap(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)\n",
    "\n",
    "# Преобразование категориальной переменной Attitude в числовую\n",
    "data['Attitude'] = data['Attitude'].map({'pro': 1, 'anti': 0})\n",
    "\n",
    "# Преобразование типов данных в числовые\n",
    "columns_to_convert = ['CRT', 'NFCS', 'CS', 'Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust', '50_75_diff_AMP']\n",
    "data[columns_to_convert] = data[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Удаление строк с NaN значениями\n",
    "data = data.dropna(subset=columns_to_convert + ['Attitude'])\n",
    "\n",
    "# Определение независимых переменных и зависимой переменной\n",
    "X = data[columns_to_convert]\n",
    "y = data['Attitude']\n",
    "\n",
    "# Добавление константы для логистической регрессии\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Подходящая логистическая регрессия\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Получение результатов\n",
    "summary = result.summary2().tables[1]\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "summary.to_excel('13.xlsx')\n",
    "\n",
    "print(\"Результаты логистической регрессии сохранены в файл '12.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3bec7b4-7bce-41e0-b671-13798f4c0e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты робастной регрессии сохранены в файл 'robust_regression_results.xlsx'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/kkh8vd7s0kzdck7rptzdy4sh0000gn/T/ipykernel_36729/477740546.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('01.csv')\n",
    "\n",
    "# Замена запятых на точки во всех переменных\n",
    "data = data.applymap(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)\n",
    "\n",
    "# Преобразование типов данных в числовые\n",
    "columns_to_convert = ['CRT', 'NFCS', 'CS', 'Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust', '50_75_diff_AMP']\n",
    "data[columns_to_convert] = data[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Удаление строк с NaN значениями\n",
    "data = data.dropna(subset=columns_to_convert)\n",
    "\n",
    "# Определение независимых переменных и зависимой переменной\n",
    "X = data[['CRT', 'NFCS', 'CS', 'Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust']]\n",
    "y = data['50_75_diff_AMP']\n",
    "\n",
    "# Добавление константы для регрессии\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Выполнение робастной регрессии\n",
    "model = sm.RLM(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Получение результатов\n",
    "summary = result.summary()\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "with pd.ExcelWriter('15.xlsx') as writer:\n",
    "    summary_df = pd.DataFrame(summary.tables[1])\n",
    "    summary_df.to_excel(writer, sheet_name='Results')\n",
    "\n",
    "print(\"Результаты робастной регрессии сохранены в файл 'robust_regression_results.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad16938e-a5f9-4185-8597-ad4296b650df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксплораторный факторный анализ завершен. Результаты сохранены в 'factor_analysis_results.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv('01.csv')\n",
    "\n",
    "# Выбор переменных для анализа\n",
    "variables = ['Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust']\n",
    "X = data[variables]\n",
    "\n",
    "# Выполнение эксплораторного факторного анализа\n",
    "fa = FactorAnalysis(n_components=2)\n",
    "X_factors = fa.fit_transform(X)\n",
    "\n",
    "# Получение нагрузок факторов\n",
    "loadings = fa.components_.T\n",
    "\n",
    "# Создание DataFrame для нагрузок\n",
    "loadings_df = pd.DataFrame(loadings, columns=['Factor 1', 'Factor 2'], index=variables)\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "with pd.ExcelWriter('18.xlsx') as writer:\n",
    "    loadings_df.to_excel(writer, sheet_name='Loadings')\n",
    "    pd.DataFrame(X_factors, columns=['Factor 1', 'Factor 2']).to_excel(writer, sheet_name='Factor Scores')\n",
    "\n",
    "print(\"Эксплораторный факторный анализ завершен. Результаты сохранены в 'factor_analysis_results.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6197c07a-c54c-4b27-9dbc-d4322cff65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Факторные нагрузки для каждой переменной:\n",
      "                   Factor 1  Factor 2\n",
      "Persuasiveness    -1.708631  0.011267\n",
      "Sharing           -1.346600 -0.162865\n",
      "Congruence        -1.117790  0.162649\n",
      "Authoritativeness -1.115964 -0.912870\n",
      "Trust             -1.511839  0.545231\n",
      "Факторные нагрузки сохранены в 'factor_loadings.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv('01.csv')\n",
    "\n",
    "# Выбор переменных для анализа\n",
    "variables = ['Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust']\n",
    "X = data[variables]\n",
    "\n",
    "# Выполнение эксплораторного факторного анализа\n",
    "fa = FactorAnalysis(n_components=2)\n",
    "fa.fit(X)\n",
    "\n",
    "# Получение нагрузок факторов\n",
    "loadings = fa.components_.T\n",
    "\n",
    "# Создание DataFrame для нагрузок\n",
    "loadings_df = pd.DataFrame(loadings, columns=[f'Factor {i+1}' for i in range(loadings.shape[1])], index=variables)\n",
    "\n",
    "# Вывод факторных нагрузок\n",
    "print(\"Факторные нагрузки для каждой переменной:\")\n",
    "print(loadings_df)\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "loadings_df.to_excel('19.xlsx', sheet_name='Loadings')\n",
    "\n",
    "print(\"Факторные нагрузки сохранены в 'factor_loadings.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce0d44bc-1740-4074-81c4-94a3f83cb918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0           0\n",
      "SBJ_ID               0\n",
      "Attitude             0\n",
      "PROCENKO_AMP_E       0\n",
      "PROCENKO_AMP_C       0\n",
      "diff_amp             0\n",
      "CRT                  0\n",
      "NFCS                 0\n",
      "CS                   0\n",
      "Speaker              0\n",
      "60_65_AMP_E          0\n",
      "60_65_AMP_C          0\n",
      "60_65_diff_AMP       0\n",
      "50_75_AMP_E          0\n",
      "50_75_AMP_C          0\n",
      "50_75_diff_AMP       0\n",
      "Persuasiveness       0\n",
      "Sharing              0\n",
      "Congruence           0\n",
      "Authoritativeness    0\n",
      "Trust                0\n",
      "Factor 1             0\n",
      "Factor 2             0\n",
      "dtype: int64\n",
      "Эксплораторный факторный анализ завершен. Результаты сохранены в 'factor_analysis_results.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv('01_1.csv')\n",
    "\n",
    "# Проверка на наличие пропущенных значений\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Выбор переменных для анализа\n",
    "variables = ['Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust']\n",
    "data_subset = data[variables]\n",
    "\n",
    "# Проведение эксплораторного факторного анализа\n",
    "fa = FactorAnalyzer(n_factors=2, rotation='varimax')\n",
    "fa.fit(data_subset)\n",
    "\n",
    "# Получение результатов\n",
    "loadings = fa.loadings_\n",
    "variance = fa.get_factor_variance()\n",
    "\n",
    "# Создание DataFrame для загрузок факторов\n",
    "loadings_df = pd.DataFrame(loadings, index=variables, columns=[f'Factor {i+1}' for i in range(2)])\n",
    "\n",
    "# Подготовка результатов для записи в Excel\n",
    "results = {\n",
    "    'Factor Loadings': loadings_df,\n",
    "    'Variance Explained': variance\n",
    "}\n",
    "\n",
    "# Запись результатов в Excel файл\n",
    "with pd.ExcelWriter('20.xlsx') as writer:\n",
    "    loadings_df.to_excel(writer, sheet_name='Factor Loadings')\n",
    "    \n",
    "    # Создание DataFrame для вариации\n",
    "    variance_df = pd.DataFrame(variance, index=['Eigenvalue', 'Variance Explained', 'Cumulative Variance'])\n",
    "    variance_df.to_excel(writer, sheet_name='Variance Explained')\n",
    "\n",
    "print(\"Эксплораторный факторный анализ завершен. Результаты сохранены в 'factor_analysis_results.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5890840-d142-43fb-89d4-2bdb6aae9ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0           0\n",
      "SBJ_ID               0\n",
      "Attitude             0\n",
      "PROCENKO_AMP_E       0\n",
      "PROCENKO_AMP_C       0\n",
      "diff_amp             0\n",
      "CRT                  0\n",
      "NFCS                 0\n",
      "CS                   0\n",
      "Speaker              0\n",
      "60_65_AMP_E          0\n",
      "60_65_AMP_C          0\n",
      "60_65_diff_AMP       0\n",
      "50_75_AMP_E          0\n",
      "50_75_AMP_C          0\n",
      "50_75_diff_AMP       0\n",
      "Persuasiveness       0\n",
      "Sharing              0\n",
      "Congruence           0\n",
      "Authoritativeness    0\n",
      "Trust                0\n",
      "dtype: int64\n",
      "Факторные баллы добавлены. Результаты сохранены в '01_.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv('01_12.csv')\n",
    "\n",
    "# Проверка на наличие пропущенных значений\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Выбор переменных для анализа\n",
    "variables = ['Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust']\n",
    "data_subset = data[variables]\n",
    "\n",
    "# Проведение эксплораторного факторного анализа\n",
    "fa = FactorAnalyzer(n_factors=2, rotation='varimax')\n",
    "fa.fit(data_subset)\n",
    "\n",
    "# Получение факторных баллов\n",
    "factor_scores = fa.transform(data_subset)\n",
    "\n",
    "# Создание DataFrame для факторных баллов\n",
    "factor_scores_df = pd.DataFrame(factor_scores, columns=[f'Factor {i+1}' for i in range(factor_scores.shape[1])])\n",
    "\n",
    "# Объединение исходных данных с факторными баллами\n",
    "data_with_factors = pd.concat([data, factor_scores_df], axis=1)\n",
    "\n",
    "# Сохранение результатов в новый CSV файл\n",
    "data_with_factors.to_csv('01.csv', index=False)\n",
    "\n",
    "print(\"Факторные баллы добавлены. Результаты сохранены в '01_.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11903a1f-25b1-44d6-b549-052775632217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def robust_regression(data_path):\n",
    "    try:\n",
    "        # Загрузка данных\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Проверка наличия необходимых столбцов\n",
    "        targets = ['Persuasiveness', 'Sharing', 'Congruence', 'Authoritativeness', 'Trust', 'Factor 1', 'Factor 2']\n",
    "        required_columns = ['Attitude', 'Speaker'] + targets\n",
    "        for col in required_columns:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"Column '{col}' is missing in the data.\")\n",
    "        \n",
    "        # Преобразование категориальных переменных в числовые\n",
    "        df['Attitude'] = LabelEncoder().fit_transform(df['Attitude'])\n",
    "        df['Speaker'] = LabelEncoder().fit_transform(df['Speaker'])\n",
    "\n",
    "        # Инициализация словаря для хранения результатов\n",
    "        results = {}\n",
    "\n",
    "        # Определение предикторов\n",
    "        predictors = ['Attitude', 'Speaker']\n",
    "\n",
    "        for target in targets:\n",
    "            X = df[predictors]\n",
    "            y = df[target]\n",
    "            # Добавление константы (intercept) для модели\n",
    "            X = sm.add_constant(X)\n",
    "            # Моделирование робастной регрессии\n",
    "            model = sm.RLM(y, X, M=sm.robust.norms.HuberT())\n",
    "            results[target] = model.fit()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{data_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def interpret_model_to_csv(results, output_path):\n",
    "    if not results:\n",
    "        print(\"No results to interpret.\")\n",
    "        return\n",
    "\n",
    "    # Список для хранения строк данных\n",
    "    rows = []\n",
    "\n",
    "    for target, result in results.items():\n",
    "        # Получение коэффициентов модели\n",
    "        coefficients = result.params\n",
    "        p_values = result.pvalues\n",
    "        conf_intervals = result.conf_int()\n",
    "\n",
    "        for param in coefficients.index:\n",
    "            coef = coefficients[param]\n",
    "            p_val = p_values[param]\n",
    "            conf_int = conf_intervals.loc[param]\n",
    "\n",
    "            # Запись данных в строку\n",
    "            row = {\n",
    "                'Target Variable': target,\n",
    "                'Predictor': param,\n",
    "                'Coefficient': coef,\n",
    "                'P-Value': p_val,\n",
    "                '95% CI Lower': conf_int[0],\n",
    "                '95% CI Upper': conf_int[1],\n",
    "                'Significance': 'Significant' if p_val < 0.05 else 'Not Significant'\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    # Создание DataFrame и сохранение в CSV\n",
    "    df_interpretation = pd.DataFrame(rows)\n",
    "    df_interpretation.to_csv(output_path, index=False)\n",
    "\n",
    "# Пример вызова функций\n",
    "data_path = '01.csv'  # Убедитесь, что путь к файлу корректный\n",
    "output_path = '19.csv'\n",
    "\n",
    "results = robust_regression(data_path)\n",
    "interpret_model_to_csv(results, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "138e8e77-2cbe-47fc-9603-f3e29ff61a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.robust.robust_linear_model import RLM\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('01.csv')\n",
    "\n",
    "# Замена запятых на точки в целевых переменных\n",
    "target_vars = ['60_65_AMP_E', '60_65_AMP_C', '60_65_diff_AMP', '50_75_AMP_E', '50_75_AMP_C', '50_75_diff_AMP']\n",
    "data[target_vars] = data[target_vars].replace(',', '.', regex=True)\n",
    "\n",
    "# Преобразование категориальных переменных\n",
    "data['Attitude'] = data['Attitude'].astype('category')\n",
    "data['Speaker'] = data['Speaker'].astype('category')\n",
    "\n",
    "# Преобразование целевых переменных в числовые значения\n",
    "for target in target_vars:\n",
    "    data[target] = pd.to_numeric(data[target], errors='coerce')\n",
    "\n",
    "# Преобразование предикторов в числовые значения\n",
    "predictors = ['CRT', 'NFCS', 'CS', 'Persuasiveness', 'Sharing', 'Congruence', \n",
    "              'Authoritativeness', 'Trust', 'Factor 1', 'Factor 2']\n",
    "\n",
    "for predictor in predictors:\n",
    "    data[predictor] = pd.to_numeric(data[predictor], errors='coerce')\n",
    "\n",
    "# Удаление строк с NaN\n",
    "data = data.dropna()\n",
    "\n",
    "# Список для хранения результатов\n",
    "results = []\n",
    "\n",
    "for target in target_vars:\n",
    "    for predictor in predictors:\n",
    "        # Создание модели\n",
    "        if predictor in ['Attitude', 'Speaker']:\n",
    "            # Создание фиктивных переменных для категориальных предикторов\n",
    "            dummies = pd.get_dummies(data[predictor], drop_first=True)\n",
    "            X = pd.concat([data[predictor] for predictor in predictors if predictor != target] + [dummies], axis=1)\n",
    "        else:\n",
    "            X = data[[predictor]]\n",
    "\n",
    "        y = data[target]\n",
    "        \n",
    "        # Добавление константы\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # Робастная регрессия\n",
    "        model = RLM(y, X).fit()\n",
    "        \n",
    "        # Сохранение результатов\n",
    "        coef = model.params[predictor]\n",
    "        p_value = model.pvalues[predictor]\n",
    "        conf_int = model.conf_int().loc[predictor]\n",
    "\n",
    "        formula = f\"{target} = \" + \" + \".join([f\"{coef:.4f} * {var}\" for var, coef in model.params.items() if var != 'const'])\n",
    "\n",
    "        results.append({\n",
    "            'Formula': formula,\n",
    "            'Dependent Variable': target,\n",
    "            'Independent Variable': predictor,\n",
    "            'Coefficient': coef,\n",
    "            'P-Value': p_value,\n",
    "            'Confidence Interval (Lower)': conf_int[0],\n",
    "            'Confidence Interval (Upper)': conf_int[1]\n",
    "        })\n",
    "\n",
    "# Создание DataFrame из результатов\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "results_df.to_excel('21.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
